ilm_sqr_error = (confirmed - ilm_pred)^2,
nn_pred = predict(nn_model, as.matrix(valid_x)),
nn_sqr_error = (confirmed - nn_pred)^2,
) %>%
summarize(
lm_mse = mean(lm_sqr_error, na.rm = TRUE),
ilm_pred = mean(ilm_sqr_error, na.rm = TRUE),
nn_mse = mean(nn_sqr_error, na.rm = TRUE)
)
history <-
fit(
object = nn_model,
x = as.matrix(train_x),
y = train_y,
batch_size = 200,
epochs = 20
)
as.matrix(train_x)
nn_model %>%
compile(
loss = "mean_squared_error",
optimizer = optimizer_rmsprop(),
metrics = "accuracy"
)
nn_model %>%
compile(
loss = "mean_squared_error",
optimizer = "adams",
metrics = "accuracy"
)
nn_model %>%
compile(
loss = "mean_squared_error",
optimizer = "adam",
metrics = "accuracy"
)
history <-
fit(
object = nn_model,
x = as.matrix(train_x),
y = train_y,
batch_size = 200,
epochs = 20
)
summary(nn_model)
nn_model %>%
compile(
loss = "mean_squared_error",
optimizer = "adam",
metrics = "accuracy"
)
history <-
fit(
object = nn_model,
x = as.matrix(train_x),
y = train_y,
batch_size = 200,
epochs = 20
)
train_y
covid
train_x
history <-
fit(
object = nn_model,
x = as.matrix(train_x),
y = train_y,
batch_size = 200,
epochs = 20
)
nn_model <-
keras_model_sequential() %>%
layer_dense(input_shape = input_shape, units = 50, activation = "relu") %>%
# layer_dropout(0.2) %>%
# layer_dense(units = 50, activation = "relu") %>%
layer_dense(1, activation = "linear")
summary(nn_model)
nn_model %>%
compile(
loss = "mean_squared_error",
optimizer = "adam",
metrics = "accuracy"
)
history <-
fit(
object = nn_model,
x = as.matrix(train_x),
y = train_y,
batch_size = 200,
epochs = 20
)
nn_model %>%
compile(
loss = "mean_squared_error",
optimizer = "adam",
metrics = "mse"
)
history <-
fit(
object = nn_model,
x = as.matrix(train_x),
y = train_y,
batch_size = 200,
epochs = 20
)
nn_model <-
keras_model_sequential() %>%
layer_dense(input_shape = input_shape, units = 50, activation = "relu") %>%
# layer_dropout(0.2) %>%
# layer_dense(units = 50, activation = "relu") %>%
layer_dense(1, activation = "softmax")
summary(nn_model)
nn_model %>%
compile(
loss = "mean_squared_error",
optimizer = "adam",
metrics = "mse"
)
history <-
fit(
object = nn_model,
x = as.matrix(train_x),
y = train_y,
batch_size = 200,
epochs = 20
)
nn_model <-
keras_model_sequential() %>%
layer_dense(input_shape = input_shape, units = 50, activation = "relu") %>%
# layer_dropout(0.2) %>%
# layer_dense(units = 50, activation = "relu") %>%
layer_dense(1, activation = "linear")
summary(nn_model)
nn_model %>%
compile(
loss = "mean_squared_error",
optimizer = "adam",
metrics = "mse"
)
history <-
fit(
object = nn_model,
x = as.matrix(train_x),
y = train_y,
batch_size = 200,
epochs = 20
)
nn_model %>%
compile(
loss = "mean_squared_error",
optimizer = "adam",
metrics = "accuracy"
)
history <-
fit(
object = nn_model,
x = as.matrix(train_x),
y = train_y,
batch_size = 200,
epochs = 20
)
nn_model %>%
compile(
loss = "mean_squared_error",
optimizer = "adam",
metrics = "mse"
)
history <-
fit(
object = nn_model,
x = as.matrix(train_x),
y = train_y,
batch_size = 200,
epochs = 20
)
nn_model %>%
compile(
loss = "mean_squared_error",
optimizer = "adam",
metrics = "rmse"
)
history <-
fit(
object = nn_model,
x = as.matrix(train_x),
y = train_y,
batch_size = 200,
epochs = 20
)
nn_model %>%
compile(
loss = "mean_squared_error",
optimizer = "adam",
metrics = "mse"
)
history <-
fit(
object = nn_model,
x = as.matrix(train_x),
y = train_y,
batch_size = 200,
epochs = 20
)
train_x
train_x %>%
summarize_all(~sum(is.na(.)))
covid_rand <-
cbind(covid %>% filter(!is.na(total_pop)), state_dummified) %>%
select(-fips, -county_name, -deaths, -state) %>%
filter_all(!is.na)
covid_rand <-
cbind(covid %>% filter(!is.na(total_pop)), state_dummified) %>%
select(-fips, -county_name, -deaths, -state) %>%
filter_all(!is.na(.))
covid_rand <-
cbind(covid %>% filter(!is.na(total_pop)), state_dummified) %>%
select(-fips, -county_name, -deaths, -state) %>%
filter_all(~ !is.na(.))
###Dividing into train, valid, test
set.seed(1234)
covid_rand <-
cbind(covid %>% filter(!is.na(total_pop)), state_dummified) %>%
select(-fips, -county_name, -deaths, -state) %>%
filter_all(~ !is.na(.)) %>%
mutate_at(vars(-confirmed, -starts_with("state")), scale) %>% ##feature scaling
mutate(
group =
sample(c(1, 2, 3), size = nrow(.), prob= c(0.6, 0.2, 0.2), replace = TRUE),
)
#train
train <- covid_rand %>% filter(group == 1) %>% select(-group)
train_x <- covid_rand %>% filter(group == 1) %>% select(-group, -confirmed)
train_y <- covid_rand %>% filter(group == 1) %>% pull(confirmed)
#validation
valid <- covid_rand %>% filter(group == 2) %>% select(-group)
valid_x <- covid_rand %>% filter(group == 2) %>% select(-group, -confirmed)
valid_y <- covid_rand %>% filter(group == 2) %>% pull(confirmed)
#test
test <- covid_rand %>% filter(group == 3) %>% select(-group)
test_x <- covid_rand %>% filter(group == 3) %>% select(-group, -confirmed)
test_y <- covid_rand %>% filter(group == 3) %>% pull(confirmed)
train_x %>%
summarize_all(~sum(is.na(.)))
#input shape of x train
input_shape <- ncol(train_x)
nn_model <-
keras_model_sequential() %>%
layer_dense(input_shape = input_shape, units = 50, activation = "relu") %>%
# layer_dropout(0.2) %>%
# layer_dense(units = 50, activation = "relu") %>%
layer_dense(1, activation = "linear")
summary(nn_model)
nn_model %>%
compile(
loss = "mean_squared_error",
optimizer = "adam",
metrics = "mse"
)
history <-
fit(
object = nn_model,
x = as.matrix(train_x),
y = train_y,
batch_size = 200,
epochs = 20
)
nn_model %>%
compile(
loss = "mean_squared_error",
optimizer = "adam",
metrics = "rmse"
)
history <-
fit(
object = nn_model,
x = as.matrix(train_x),
y = train_y,
batch_size = 200,
epochs = 20
)
nn_model %>%
compile(
loss = "mean_squared_error",
optimizer = "adam",
metrics = "mse"
)
history <-
fit(
object = nn_model,
x = as.matrix(train_x),
y = train_y,
batch_size = 200,
epochs = 20
)
nn_model <-
keras_model_sequential() %>%
layer_dense(input_shape = input_shape, units = 50, activation = "relu") %>%
layer_dropout(0.2) %>%
layer_dense(units = 50, activation = "relu") %>%
layer_dense(1, activation = "linear")
summary(nn_model)
nn_model %>%
compile(
loss = "mean_squared_error",
optimizer = "adam",
metrics = "mse"
)
history <-
fit(
object = nn_model,
x = as.matrix(train_x),
y = train_y,
batch_size = 200,
epochs = 20
)
nn_model <-
keras_model_sequential() %>%
layer_dense(input_shape = input_shape, units = 20, activation = "relu") %>%
layer_dropout(0.2) %>%
layer_dense(units = 50, activation = "relu") %>%
layer_
nn_model <-
keras_model_sequential() %>%
layer_dense(input_shape = input_shape, units = 20, activation = "relu") %>%
layer_dropout(0.2) %>%
layer_dense(units = 50, activation = "relu") %>%
# layer_
layer_dense(1, activation = "linear")
summary(nn_model)
nn_model %>%
compile(
loss = "mean_squared_error",
optimizer = "adam",
metrics = "mse"
)
history <-
fit(
object = nn_model,
x = as.matrix(train_x),
y = train_y,
batch_size = 200,
epochs = 20
)
nn_model <-
keras_model_sequential() %>%
layer_dense(input_shape = input_shape, units = 20, activation = "relu") %>%
# layer_dropout(0.2) %>%
layer_dense(units = 20, activation = "relu") %>%
layer_dense(units = 20, activation = "relu") %>%
layer_dense(units = 20, activation = "relu") %>%
layer_dense(units = 20, activation = "relu") %>%
layer_dense(units = 20, activation = "relu") %>%
layer_dense(units = 20, activation = "relu") %>%
layer_dense(1, activation = "linear")
summary(nn_model)
nn_model %>%
compile(
loss = "mean_squared_error",
optimizer = "adam",
metrics = "mse"
)
history <-
fit(
object = nn_model,
x = as.matrix(train_x),
y = train_y,
batch_size = 200,
epochs = 20
)
history <-
fit(
object = nn_model,
x = as.matrix(train_x),
y = train_y,
batch_size = 200,
epochs = 500
)
lm_fit <- lm(confirmed ~ ., data = train)
lm_fit <- lm(confirmed ~ ., data = train)
### Linear model with interactions
```{r}
lm_inter_fit <- lm(confirmed ~ . + .:., data = train)
```
lm_fit <- lm(confirmed ~ ., data = train)
lm_inter_fit <- lm(confirmed ~ . + .:., data = train)
train %>%
mutate(
lm_pred = predict(lm_fit, train_x),
lm_sqr_error = (confirmed - lm_pred)^2,
ilm_pred = predict(lm_inter_fit, train_x),
ilm_sqr_error = (confirmed - ilm_pred)^2,
nn_pred = predict(nn_model, as.matrix(train_x)),
nn_sqr_error = (confirmed - nn_pred)^2,
) %>%
summarize(
lm_mse = mean(lm_sqr_error, na.rm = TRUE),
ilm_pred = mean(ilm_sqr_error, na.rm = TRUE),
nn_mse = mean(nn_sqr_error, na.rm = TRUE)
)
valid %>%
mutate(
lm_pred = predict(lm_fit, valid_x),
lm_sqr_error = (confirmed - lm_pred)^2,
ilm_pred = predict(lm_inter_fit, valid_x),
ilm_sqr_error = (confirmed - ilm_pred)^2,
nn_pred = predict(nn_model, as.matrix(valid_x)),
nn_sqr_error = (confirmed - nn_pred)^2,
) %>%
summarize(
lm_mse = mean(lm_sqr_error, na.rm = TRUE),
ilm_pred = mean(ilm_sqr_error, na.rm = TRUE),
nn_mse = mean(nn_sqr_error, na.rm = TRUE)
)
nn_model %>%
compile(
loss = "mean_squared_error",
optimizer = "adam",
metrics = c("mse", "mae")
)
history <-
fit(
object = nn_model,
x = as.matrix(train_x),
y = train_y,
batch_size = 200,
epochs = 500
)
###Dividing into train, valid, test
set.seed(1234)
covid_rand <-
cbind(covid %>% filter(!is.na(total_pop)), state_dummified) %>%
select(-fips, -county_name, -state) %>%
filter_all(~ !is.na(.)) %>% #Dropping all variables with NAs
mutate_at(vars(-confirmed, -starts_with("state")), scale) %>% #feature scaling
mutate(
group =
sample(c(1, 2, 3), size = nrow(.), prob= c(0.6, 0.2, 0.2), replace = TRUE),
)
#train
train <- covid_rand %>% filter(group == 1) %>% select(-group)
train
#train
train <- covid_rand %>% filter(group == 1) %>% select(-group)
train_x <- covid_rand %>% filter(group == 1) %>% select(-group, -deaths)
train_y <- covid_rand %>% filter(group == 1) %>% pull(deaths)
#validation
valid <- covid_rand %>% filter(group == 2) %>% select(-group)
valid_x <- covid_rand %>% filter(group == 2) %>% select(-group, -deaths)
valid_y <- covid_rand %>% filter(group == 2) %>% pull(deaths)
#test
test <- covid_rand %>% filter(group == 3) %>% select(-group)
test_x <- covid_rand %>% filter(group == 3) %>% select(-group, -deaths)
test_y <- covid_rand %>% filter(group == 3) %>% pull(deaths)
lm_fit <- lm(deaths ~ ., data = train)
lm_inter_fit <- lm(deaths ~ . + .:., data = train)
library(keras)
#input shape of x train
input_shape <- ncol(train_x)
nn_model <-
keras_model_sequential() %>%
layer_dense(input_shape = input_shape, units = 20, activation = "relu") %>%
# layer_dropout(0.2) %>%
layer_dense(units = 20, activation = "relu") %>%
layer_dense(units = 20, activation = "relu") %>%
layer_dense(units = 20, activation = "relu") %>%
layer_dense(units = 20, activation = "relu") %>%
layer_dense(units = 20, activation = "relu") %>%
layer_dense(units = 20, activation = "relu") %>%
layer_dense(1, activation = "linear")
summary(nn_model)
nn_model %>%
compile(
loss = "mean_squared_error",
optimizer = "adam",
metrics = c("mse", "mae")
)
history <-
fit(
object = nn_model,
x = as.matrix(train_x),
y = train_y,
batch_size = 200,
epochs = 500
)
train %>%
mutate(
lm_pred = predict(lm_fit, train_x),
lm_sqr_error = (deaths - lm_pred)^2,
ilm_pred = predict(lm_inter_fit, train_x),
ilm_sqr_error = (deaths - ilm_pred)^2,
nn_pred = predict(nn_model, as.matrix(train_x)),
nn_sqr_error = (deaths - nn_pred)^2,
) %>%
summarize(
lm_mse = mean(lm_sqr_error, na.rm = TRUE),
ilm_pred = mean(ilm_sqr_error, na.rm = TRUE),
nn_mse = mean(nn_sqr_error, na.rm = TRUE)
)
valid %>%
mutate(
lm_pred = predict(lm_fit, valid_x),
lm_sqr_error = (deaths - lm_pred)^2,
ilm_pred = predict(lm_inter_fit, valid_x),
ilm_sqr_error = (deaths - ilm_pred)^2,
nn_pred = predict(nn_model, as.matrix(valid_x)),
nn_sqr_error = (deaths - nn_pred)^2,
) %>%
summarize(
lm_mse = mean(lm_sqr_error, na.rm = TRUE),
ilm_pred = mean(ilm_sqr_error, na.rm = TRUE),
nn_mse = mean(nn_sqr_error, na.rm = TRUE)
)
